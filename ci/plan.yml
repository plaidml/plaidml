---
CONST:
  efficiency_baseline: tf-cuda-gp100gl

  gpu_flops:
    # nvidia
    gt650m: 605.77
    gtx780: 3819.42
    gtx1050: 1733.15
    gtx1070: 7282.69
    gtx1080: 9380.39
    gtx1080ti: 12571.25
    gp100gl: 10736.02
    gv100gl: 14757.70
    # amd
    r560: 1815.01
    rx480: 5950.39
    r9nano: 8077.04
    vega: 12697.10
    gfx900: 11300.84
    gfx803: 3573.79
    gfx906: 13379.70
    vega56: 4342.63
    # mali
    t628: 34.05
    # intel
    hd4000: 247.14
    hd505: 213.80
    hd630: 417.22
    uhd630: 454.72
    iris655: 757.84
    neo: 1084.50

PLATFORMS:
  tf-cuda-gtx780:
    variant: linux_x86_64
  tf-cuda-gtx1070:
    variant: linux_x86_64
  tf-dnnl-cpu:
    variant: linux_x86_64
  pml-mtl-uhd630:
    variant: macos_x86_64
  pml-llvm-cpu:
    variant: linux_x86_64
  tf-cuda-gp100gl:
    variant: linux_x86_64
  pml-ocl-gfx900:
    variant: linux_x86_64
  pml-ocl-gp100gl:
    variant: linux_x86_64
  pml-ocl-gv100gl:
    variant: linux_x86_64
  pml-ocl-gen:
    variant: linux_x86_64
  pml-vk-gen:
    variant: linux_x86_64
  pml-ocl-gfx804:
    variant: windows_x86_64

VARIANTS:
  linux_x86_64:
    arch: manylinux1_x86_64
    system: Linux
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  linux_x86_64_dbg:
    bazel_config: dbg
    arch: manylinux1_x86_64
    system: Linux
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  macos_x86_64:
    arch: macosx_10_10_x86_64
    system: Darwin
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  macos_x86_64_dbg:
    bazel_config: dbg
    arch: macosx_10_10_x86_64
    system: Darwin
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  # Temporarily remove until build agents are online again
  # windows_x86_64:
  #   arch: win_amd64
  #   system: Windows
  #   env:
  #     PLAIDML_DEVICE: llvm_cpu.0
  #     PLAIDML_TARGET: llvm_cpu

SUITES:
  smoke:
    platforms:
      pml-llvm-cpu:
        pipelines: [nightly, plaidml]
      pml-ocl-gen:
        pipelines: [nightly, plaidml]
    params:
      plaidml:
        batch_sizes: [1]
      ci:
        batch_sizes: [1]
      nightly:
        batch_sizes: [1]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
      - plaidbench-{version}-py2.py3-none-any.whl
    timeout: 5
    conda_env: ci/conda/tensorflow.yml
    compare: no
    eventlog: yes
    runner: plaidbench
    args:
      - --results={results}
      - --no-kernel-timing
      - --print-stacktraces
      - --no-warmup
      - --examples=1
      - keras
      - "{workload}"
    workloads:
      resnet50:
        precision: untested

  base:
    platforms:
      pml-llvm-cpu:
        pipelines: [nightly, plaidml, ci]
      pml-ocl-gen:
        pipelines: [nightly, plaidml, ci]
    params:
      ci:
        batch_sizes: [0]
      plaidml:
        batch_sizes: [0]
      nightly:
        batch_sizes: [0]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
    timeout: 30
    conda_env: ci/conda/tensorflow.yml
    compare: no
    runner: python
    workloads:
      backend:
        args: [backend_test.py]
        cwd: plaidml/bridge/keras
        conda_env: ci/conda/keras_backend_test.yml
        precision: untested
        skip_platforms:
          - pml-vk-gen
          - pml-ocl-gen
      edsl_cc_test:
        runner: cc_test
        cwd: tmp/input
        precision: untested
        skip_platforms:
          - pml-llvm-cpu
        platform_overrides:
          pml-vk-gen:
            args:
              - --plaidml_target=intel_gen
              - --plaidml_device=vulkan.0
              - --skip_test_file=edsl_test-skip.intel_gen.txt
          pml-ocl-gen:
            args:
              - --plaidml_target=intel_gen_ocl_spirv
              - --plaidml_device=opencl.0
              - --skip_test_file=edsl_test-skip.intel_gen_ocl_spirv.txt

      # mnist_mlp:
      #   args: [mnist_mlp_test.py]
      #   precision: untested
      #   soft_fail: true
      # regression:
      #   args: [regression_test.py]
      #   precision: untested
      #   soft_fail: true
      trivial_model:
        args: [trivial_model_test.py]
        cwd: plaidml/bridge/keras
        precision: untested
        skip_platforms:
          - pml-ocl-gen

  infer:
    platforms:
      pml-llvm-cpu:
        pipelines: [nightly, plaidml, ci]
      pml-ocl-gen:
        pipelines: [nightly, plaidml, ci]
    params:
      ci:
        batch_sizes: [1]
      plaidml:
        batch_sizes: [1]
      nightly:
        batch_sizes: [1]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
      - plaidbench-{version}-py2.py3-none-any.whl
    timeout: 10
    conda_env: ci/conda/tensorflow.yml
    runner: plaidbench
    args:
      - --results={results}
      - --batch-size={batch_size}
      - --no-kernel-timing
      - --print-stacktraces
      - keras
      - "{workload}"
    workloads:
      imdb_lstm:
        precision: high
        skip_platforms:
          - pml-llvm-cpu
          - pml-vk-gen
          - pml-ocl-gen
          - tf-dnnl-cpu
        perf_threshold: 0.7
      inception_v3:
        skip_platforms:
          - pml-vk-gen
          - pml-ocl-gen
        precision: high
        platform_overrides:
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml
          pml-llvm-cpu:
            prepend_args: [--examples=64]
            soft_fail: true # performance regression
          pml-ocl-gfx804:
            prepend_args: [--examples=64]
          pml-ocl-gen:
            prepend_args: [--examples=512]
          pml-mtl-uhd630:
            prepend_args: [--examples=256]
      mobilenet:
        precision: high
        skip_platforms:
          - pml-vk-gen
          - pml-ocl-gen
        platform_overrides:
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml
      mobilenet_v2:
        precision: high
        platform_overrides:
          pml-llvm-cpu:
            soft_fail: true # performance regression
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml
        skip_platforms:
          - pml-vk-gen
          - pml-ocl-gen
      resnet50:
        precision: high
        platform_overrides:
          pml-vk-gen:
            prepend_args: [--examples=128]
            perf_threshold: 0.33
          pml-ocl-gen:
            prepend_args: [--examples=4]
            perf_threshold: 0.33
          pml-llvm-cpu:
            prepend_args: [--examples=128]
          pml-ocl-gfx804:
            prepend_args: [--examples=128]
          pml-mtl-uhd630:
            prepend_args: [--examples=256]
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml
      vgg19:
        precision: high
        platform_overrides:
          pml-llvm-cpu:
            prepend_args: [--examples=64]
            soft_fail: true # performance regression
          pml-ocl-gfx804:
            prepend_args: [--examples=64]
          pml-ocl-gen:
            prepend_args: [--examples=256]
          pml-mtl-uhd630:
            prepend_args: [--examples=256]
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml
        skip_platforms:
          - pml-mtl-uhd630
          - pml-vk-gen
          - pml-ocl-gen
      xception:
        precision: high
        skip_platforms:
          - pml-vk-gen
          - pml-ocl-gen
        platform_overrides:
          pml-llvm-cpu:
            prepend_args: [--examples=64]
          pml-ocl-gfx804:
            prepend_args: [--examples=64]
          pml-ocl-gv100gl:
            prepend_args: [--examples=512]
          pml-ocl-gen:
            prepend_args: [--examples=256]
            perf_threshold: 0.7
          pml-mtl-uhd630:
            prepend_args: [--examples=64]
            soft_fail: true
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml

  train:
    platforms: {}
    params:
      ci:
        batch_sizes: [1, 32]
      nightly:
        batch_sizes: [1, 32]
      train:
        batch_sizes: [16, 32]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
      - plaidbench-{version}-py2.py3-none-any.whl
    timeout: 5
    conda_env: ci/conda/ml_gpu.yml
    cwd: plaidbench
    runner: python
    examples: 256
    workloads:
      inception_v3_train:
        # Expecting a memory error -- the versions that are too big will skip;
        # passing versions will pass; and non-memory errors will still error
        expected: "CL_MEM_OBJECT_ALLOCATION_FAILURE"
        precision: low
        args:
          - plaidbench.py
          - inception_v3
          - --train
          - --print-stacktraces
          - --batch-size={batch_size}
      resnet50_train:
        precision: low
        args:
          - plaidbench.py
          - resnet50
          - --train
          - --print-stacktraces
          - --batch-size={batch_size}
      vgg19_train:
        precision: low
        args:
          - plaidbench.py
          - vgg19
          - --train
          - --print-stacktraces
          - --batch-size={batch_size}
      xception_train:
        precision: low
        args:
          - plaidbench.py
          - xception
          - --train
          - --print-stacktraces
          - --batch-size={batch_size}
      mobilenet_train:
        precision: low
        args:
          - plaidbench.py
          - mobilenet
          - --train
          - --print-stacktraces
          - --batch-size={batch_size}
