{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "Vertex.AI Interactive Event Analysis\n",
    "=========================================\n",
    "\n",
    "This interactive notebook can be used for exploring events generated by Vertex.AI components.\n",
    "\n",
    "To use it, you'll first need to produce an event log.  The way you do this varies with the various components (since they're configured in different ways).\n",
    "\n",
    "* With the Tile server, you'll want to add something like the following stanza to your JSON _server.conf_:\n",
    "\n",
    "      \"eventlog\": {\n",
    "        \"@type\": \"type.vertex.ai/vertexai.eventing.file.proto.EventLog\",\n",
    "        \"filename\": \"eventlog.gz\"\n",
    "       },\n",
    "       \"event_tracking_mode\": \"EVENT_TRACKING_MODE_GLOBAL\"\n",
    "     \n",
    "  When run with this configuration, the server will write a file, _eventlog.gz_, on shutdown (which you can trigger with a Ctrl-C).\n",
    "\n",
    "     \n",
    "* With the PlaidML Python backends, you can typically set an environment variable:\n",
    "\n",
    "       PLAIDML_EVENTLOG_FILENAME=eventlog.gz\n",
    "     \n",
    "  This will cause events to be logged to _eventlog.gz_ on shutdown.\n",
    "\n",
    "Next, build this notebook's Python dependencies:\n",
    "\n",
    "    bazel build //base/context/analysis\n",
    "    \n",
    "By default, the notebook will look for _eventlog.gz_ in your home directory.  If that's wrong, you'll want to tweak the *scope.read_eventlog()* line below.\n",
    "\n",
    "Once _eventlog.gz_ is in place, and the dependencies have been built, you can run the notebook, and start adding your own cells to explore the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Add some useful imports; make sure the Python path is configured correctly, &c.\n",
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "# N.B. We use 'inline' since our test infrastructure doesn't support 'notebook'.\n",
    "# Using 'notebook' provides some interactive controls for the diagrams.\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import imp\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "\n",
    "class ManifestLoader(object):\n",
    "    def __init__(self, path, filename):\n",
    "        self._path = path\n",
    "        self._filename = filename\n",
    "        \n",
    "    def load_module(self, fullname):\n",
    "        if fullname in sys.modules:\n",
    "            mod = sys.modules[fullname]\n",
    "        else:\n",
    "            mod = imp.new_module(fullname)\n",
    "            mod.__name__ = fullname\n",
    "            mod.__package__ = fullname.split('.', 1)[0]\n",
    "            mod.__builtins__ = __builtins__\n",
    "            mod.__path__ = [mod.__package__]\n",
    "            sys.modules[fullname] = mod\n",
    "            names = fullname.rsplit('.', 1)\n",
    "            if len(names) > 1:\n",
    "                setattr(sys.modules[names[0]], names[1], mod)\n",
    "        if self._filename:\n",
    "            mod.__file__ = self._filename\n",
    "            lmod = imp.load_source(fullname, self._filename)\n",
    "            for attrname in dir(lmod):\n",
    "                setattr(mod, attrname, getattr(lmod, attrname))\n",
    "        return mod\n",
    "\n",
    "\n",
    "class ManifestFinder(object):\n",
    "    def __init__(self, prefixes, manifest_filename):\n",
    "        self._known = {}\n",
    "        self._prefixes = prefixes\n",
    "        with open(manifest_filename, 'r') as manifest:\n",
    "            for line in manifest:\n",
    "                parts = line.split()\n",
    "                parts.append(None)\n",
    "                self._known[parts[0]] = parts[1]\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        for prefix in self._prefixes:\n",
    "            if prefix:\n",
    "                base = '/'.join([prefix] + fullname.split('.'))\n",
    "            else:\n",
    "                base = '/'.join(fullname.split('.'))\n",
    "            for ext in ['/__init__.py', '.py']:\n",
    "                fname = base + ext\n",
    "                if fname in self._known:\n",
    "                    return ManifestLoader(fname, self._known[fname])\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    initialized_notebook\n",
    "except:\n",
    "    runfiles = os.path.join('..', '..', '..', 'bazel-bin', 'base', 'context', 'analysis', 'analysis.runfiles')\n",
    "    if os.path.exists(os.path.join(runfiles, 'vertexai')) and os.path.exists(os.path.join(runfiles, 'vertexai_plaidml')):\n",
    "        sys.path.append(os.path.join(runfiles))\n",
    "    elif os.path.exists(os.path.join(runfiles, 'MANIFEST')):\n",
    "        sys.meta_path.append(ManifestFinder(['vertexai', 'vertexai_plaidml', 'protobuf/python', 'protobuf/src', 'six_archive'],\n",
    "                                            os.path.join(runfiles, 'MANIFEST')))\n",
    "    elif os.path.exists(os.path.join('..', 'MANIFEST')):\n",
    "        sys.meta_path.append(ManifestFinder(['vertexai', 'vertexai_plaidml', 'protobuf/python', 'protobuf/src', 'six_archive'],\n",
    "                                            os.path.join('..', 'MANIFEST')))\n",
    "    else:\n",
    "        raise Exception('Please build //base/context/analysis')\n",
    "    initialized_notebook = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# With the Python path configured, the Bazel-built code can be loaded.\n",
    "import base.context.analysis as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the raw events, and make them useful.\n",
    "scope = ca.Scope()\n",
    "if 'PLAIDML_EVENTLOG_FILENAME' in os.environ:\n",
    "    scope.read_eventlog(os.environ['PLAIDML_EVENTLOG_FILENAME'])\n",
    "else:\n",
    "    scope.read_eventlog(os.path.expanduser('~/eventlog.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build up some stats on the kernels...\n",
    "runs = filter(lambda evt: evt.verb == 'tile::hal::opencl::Executing', scope.events.itervalues())\n",
    "times = {}\n",
    "for r in runs:\n",
    "    kuuid = r.ocl_runinfo.kernel_uuid\n",
    "    try:\n",
    "        kname = scope.events[kuuid].ocl_kernelinfo.kname\n",
    "    except:\n",
    "        print('{} -> {}'.format(r, r.ocl_runinfo))\n",
    "        continue\n",
    "    prev = times.get(kname, (0., 0, kuuid))\n",
    "    times[kname] = (r.elapsed_time + prev[0], prev[1]+1, prev[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at mean OpenCL kernel execution times, because they're often interesting.\n",
    "means = {}\n",
    "for kname in times:\n",
    "    means[kname] = times[kname][0] / times[kname][1]\n",
    "knames_by_mean_runtime = means.keys()\n",
    "knames_by_mean_runtime.sort(key=lambda kname: means[kname], reverse=True)\n",
    "for kname in knames_by_mean_runtime:\n",
    "    print('{}: {}'.format(kname, datetime.timedelta(seconds=means[kname])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's turn the top 80 mean kernel execution times into a bar graph.\n",
    "top_knames = knames_by_mean_runtime[:80]\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(range(len(top_knames)), [means[kname] for kname in top_knames])\n",
    "plt.xticks(range(len(top_knames)), top_knames, rotation=90)\n",
    "fig.tight_layout(pad=2.)\n",
    "plt.xlabel('Kernel')\n",
    "plt.ylabel('Mean Runtime(seconds)')\n",
    "plt.title('Mean Runtimes by Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the highest-mean-runtime kernel:\n",
    "kuuid = times[knames_by_mean_runtime[0]][2]\n",
    "kevt = scope.events[kuuid]\n",
    "kinfo = kevt.ocl_kernelinfo\n",
    "print(kinfo.src.decode('string_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And its program:\n",
    "print('Kernel {}\\'s program was:\\n{}'.format(kinfo.kname, kevt.hal_compilationinfo.program.code.decode('string_escape')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total runtimes are also interesting.\n",
    "totals = {}\n",
    "for kname in times:\n",
    "    totals[kname] = times[kname][0]\n",
    "knames_by_total_runtime = totals.keys()\n",
    "knames_by_total_runtime.sort(key=lambda kname: totals[kname], reverse=True)\n",
    "for kname in knames_by_total_runtime:\n",
    "    print('{}: {}'.format(kname, datetime.timedelta(seconds=totals[kname])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's turn the top 80 total kernel execution times into a bar graph.\n",
    "top_knames = knames_by_total_runtime[:80]\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(range(len(top_knames)), [totals[kname] for kname in top_knames])\n",
    "plt.xticks(range(len(top_knames)), top_knames, rotation=90)\n",
    "fig.tight_layout(pad=2.)\n",
    "plt.xlabel('Kernel')\n",
    "plt.ylabel('Total Runtime(seconds)')\n",
    "plt.title('Total Runtimes by Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the highest-total-runtime kernel:\n",
    "kuuid = times[knames_by_total_runtime[0]][2]\n",
    "kevt = scope.events[kuuid]\n",
    "kinfo = kevt.ocl_kernelinfo\n",
    "print(kinfo.src.decode('string_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# And its program:\n",
    "print('Kernel {}\\'s program was:\\n{}'.format(kinfo.kname, kevt.hal_compilationinfo.program.code.decode('string_escape')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much memory did its program take up?\n",
    "total = 0\n",
    "for size, count in kevt.hal_compilationinfo.alloc_sizes.iteritems():\n",
    "    total += size * count\n",
    "print('Kernel {}\\'s program used {} bytes of temporary memory:'.format(kinfo.kname, total))\n",
    "for size, count in kevt.hal_compilationinfo.alloc_sizes.iteritems():\n",
    "    print('  {} alloc(s) of size {}'.format(count, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the actual program?\n",
    "print('Kernel {}\\'s program was:\\n{}'.format(kinfo.kname, kevt.hal_compilationinfo.program.code.decode('string_escape')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# It can also be interesting to look at what happens across an entire batch invocation.\n",
    "invocations = filter(lambda evt: evt.verb == 'plaidml::invoker::ScheduleInvocation', scope.events.itervalues())\n",
    "evt = invocations[10]\n",
    "\n",
    "# Compute the buffer mapping events that occur after this invocation and before the next invocation.\n",
    "mapping_window_end = 0\n",
    "for e in invocations:\n",
    "    if mapping_window_end < e.start_time:\n",
    "        mapping_window_end = e.start_time\n",
    "for e in invocations:\n",
    "    if e.start_time < mapping_window_end and evt.end_time < e.start_time:\n",
    "        mapping_window_end = e.start_time\n",
    "mappings = filter(lambda e: e.verb == 'tile::MapCurrent' and evt.end_time <= e.start_time and e.end_time <= mapping_window_end,\n",
    "                  scope.events.itervalues())\n",
    "\n",
    "def depth_first_iter(event):\n",
    "    pending = [event]\n",
    "    while pending:\n",
    "        event = pending.pop()\n",
    "        yield event\n",
    "        children = list(event.children)\n",
    "        children.sort(key=lambda e: e.start_time, reverse=True)\n",
    "        pending.extend(children)\n",
    "        \n",
    "def events_iter():\n",
    "    iterators = [depth_first_iter(evt)]\n",
    "    iterators.extend([depth_first_iter(m) for m in mappings])\n",
    "    return itertools.chain(*iterators)\n",
    "\n",
    "verb_indicies = {}\n",
    "event_count = 0\n",
    "max_elapsed_time = 0\n",
    "max_executing_kname = ''\n",
    "for e in events_iter():\n",
    "    event_count += 1\n",
    "    if e.verb not in verb_indicies:\n",
    "        index = len(verb_indicies)\n",
    "        verb_indicies[e.verb] = index\n",
    "    if e.verb == 'tile::hal::opencl::Executing' and e.elapsed_time > max_elapsed_time:\n",
    "        max_elapsed_time = e.elapsed_time\n",
    "        max_executing_kname = scope.events[e.ocl_runinfo.kernel_uuid].ocl_kernelinfo.kname\n",
    "\n",
    "fig = plt.figure(figsize=(10, event_count / 5.))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "idx = 1\n",
    "yticks = []\n",
    "colormap = mpl.cm.get_cmap('jet')\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=len(verb_indicies))\n",
    "for e in events_iter():\n",
    "    try:\n",
    "        label = scope.events[e.ocl_runinfo.kernel_uuid].ocl_kernelinfo.kname + ' '\n",
    "    except KeyError:\n",
    "        label = ''\n",
    "    ax.barh(event_count-idx,\n",
    "            width=e.elapsed_time,\n",
    "            left=e.start_time,\n",
    "            align='center',\n",
    "            color=colormap(norm(verb_indicies[e.verb])))\n",
    "    yticks.append(label + '.'.join(e.verb.split('::')[-2:]))\n",
    "    idx += 1\n",
    "yticks.reverse()\n",
    "plt.yticks(range(len(yticks)), yticks)\n",
    "ax.set_ylim(bottom=-1, top=len(yticks))\n",
    "ax.grid(b=True)\n",
    "fig.tight_layout(pad=2.)\n",
    "fig.autofmt_xdate()\n",
    "plt.xlabel('Timestamp (seconds)')\n",
    "plt.title('Program Run')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun, let's dump the longest-running kernel code.\n",
    "# We're doing this by kernel name to make it easy to interactively swap in other kernels;\n",
    "# just change max_executing_kname here.\n",
    "build_event = scope.events[times[max_executing_kname][2]]\n",
    "print(build_event.ocl_kernelinfo.src.decode('string_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Also just for fun: let's dump the device info for that kernel.\n",
    "device_event = scope.events[build_event.ocl_buildinfo.device_uuid]\n",
    "print(device_event.ocl_deviceinfo)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
